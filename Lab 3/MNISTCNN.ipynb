{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ornkjp7YPwdf"
      },
      "source": [
        "We first import the necessary packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "y6U3GHRtEiSV"
      },
      "outputs": [],
      "source": [
        "# install libraries\n",
        "!pip install scikeras\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sklearn as sk\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from tensorflow import keras\n",
        "import tensorflow as tf\n",
        "import random as python_random\n",
        "from sklearn.pipeline import Pipeline\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from scikeras.wrappers import KerasClassifier\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "niNt_wglLQlL"
      },
      "source": [
        "We load the train and test data sets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tv9uGCUEFWy1",
        "outputId": "a84013ae-4a84-4055-8d92-cd0e3df0bd39"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "# load dataset and transform to pandas dataframe\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2FPMIpLBLVTw"
      },
      "source": [
        "We one hot encode our data, the number of classes are 10 (0 through 9)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "S-U9Szoj9-Zb"
      },
      "outputs": [],
      "source": [
        "y_train_encoded = to_categorical(y_train, num_classes=10)\n",
        "y_test_encoded = to_categorical(y_test, num_classes=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jEP2-ZKeLkVk"
      },
      "source": [
        "Function to create a sequntial model to be trained."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "4vFphR70YAwP"
      },
      "outputs": [],
      "source": [
        "def create_model(learning_rate=0.001, num_filters=16):\n",
        "  model = keras.models.Sequential()\n",
        "  #Define filters and convolutional layers here\n",
        "  model.add(keras.layers.Conv2D(filters=num_filters, kernel_size=(3, 3),\n",
        "  activation='relu', input_shape=(28, 28, 1)))\n",
        "  #Add a maxpooling layer\n",
        "  model.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "  #Flatten the output and give it to a fully connected layer\n",
        "  model.add(keras.layers.Flatten())\n",
        "  #One hidden layer maps the flattened neurons to output\n",
        "  model.add(keras.layers.Dense(10, activation='softmax'))\n",
        "  optimizer = keras.optimizers.Adam(learning_rate=learning_rate)  # Set the learning rate\n",
        "  model.compile(optimizer='adam', loss='categorical_crossentropy',\n",
        "  metrics=['accuracy'])\n",
        "  return model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vHTt5WqklZfO"
      },
      "source": [
        "We iterate through 4 combinations of learning rates and number of filters.\n",
        "We use stratified k fold with k = 5 during parameter exploration for each set of paramters.\n",
        "Best paramters are determined using highest f1 score of the 4 combinations.\n",
        "We use our training data for Stratified K fold cross validation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8yFQNDQZIyuT"
      },
      "outputs": [],
      "source": [
        "# initialize stratified k fold\n",
        "\n",
        "learning_rates = [0.001, 0.01]\n",
        "num_filters = [16, 32]\n",
        "\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "results = []\n",
        "\n",
        "for lr in learning_rates:\n",
        "    for nf in num_filters:\n",
        "        # Create a Keras model for the current hyperparameters\n",
        "        model = create_model(learning_rate=lr, num_filters=nf)\n",
        "\n",
        "        # Create a Scikit-learn pipeline\n",
        "        pipeline = sk.pipeline.Pipeline([\n",
        "            ('classifier', KerasClassifier(model=create_model, epochs=10, batch_size=32, verbose=0))\n",
        "        ])\n",
        "\n",
        "        # Lists to store results for each fold\n",
        "        f1_scores = []\n",
        "\n",
        "        for train_index, test_index in skf.split(X_train, y_train):\n",
        "            X_train_fold, X_test_fold = X_train[train_index], X_train[test_index]\n",
        "            y_train_fold, y_test_fold = y_train_encoded[train_index], y_train_encoded[test_index]\n",
        "\n",
        "            # Fit the pipeline on the training data\n",
        "            pipeline.fit(X_train_fold, y_train_fold)\n",
        "\n",
        "            # Predict on the test data\n",
        "            y_pred = pipeline.predict(X_test_fold)\n",
        "\n",
        "            # Calculate the F1 score for this fold\n",
        "            f1 = f1_score(y_true = y_test_fold.argmax(axis=1), y_pred = y_pred.argmax(axis=1), average='macro')\n",
        "            f1_scores.append(f1)\n",
        "\n",
        "        # Calculate the mean F1 score for these hyperparameters\n",
        "        mean_f1 = np.mean(f1_scores)\n",
        "        results.append((lr, nf, mean_f1))\n",
        "        print(f\"Learning Rate: {lr}, Num Filters: {nf}, Mean F1 Score: {mean_f1}\")\n",
        "\n",
        "# Find the hyperparameters with the best F1 score\n",
        "best_params = max(results, key=lambda x: x[2])\n",
        "print(f\"Best Hyperparameters: Learning Rate {best_params[0]}, Num Filters {best_params[1]}, Mean F1 Score {best_params[2]}\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TgOXqtPvOv9t"
      },
      "source": [
        "We now train a new model on the best parameters and the entire data set inside a pipeline.\n",
        "\n",
        "We then test it on the test MNIST data set loaded earlier.\n",
        "\n",
        "We report the classification accuracy as this is one of the most commonly used metrics for MNIST data sets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vuum_1WtZU1Q"
      },
      "outputs": [],
      "source": [
        "# Best hyperparameters\n",
        "best_lr, best_nf, _ = best_params\n",
        "\n",
        "# Create a Keras model with the best hyperparameters\n",
        "best_model = create_model(learning_rate=best_lr, num_filters=best_nf)\n",
        "\n",
        "# Best hyperparameters\n",
        "best_lr, best_nf, _ = best_params\n",
        "\n",
        "# Create a Keras model with the best hyperparameters\n",
        "best_model = create_model(learning_rate=best_lr, num_filters=best_nf)\n",
        "\n",
        "# Create a Scikit-learn pipeline with the best model\n",
        "pipeline = sk.pipeline.Pipeline([\n",
        "    ('classifier', KerasClassifier(model=best_model, epochs=10, batch_size=32, verbose=0))\n",
        "])\n",
        "\n",
        "\n",
        "# Fit the pipeline with the best model on the full training dataset\n",
        "pipeline.fit(X_train, y_train_encoded)\n",
        "\n",
        "# Evaluate the model on the test dataset using the pipeline and get accuracy\n",
        "test_accuracy = pipeline.score(X_test, y_test_encoded)\n",
        "\n",
        "# Report the classification accuracy on the test dataset\n",
        "print(f\"Classification Accuracy for learning rate {best_lr} and number of neurons {best_nf}: {test_accuracy}\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}